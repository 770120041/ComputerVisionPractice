{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from numpy import floor\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.spatial.distance import cdist\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\"\n",
    "        Function to get gaussian deritive kernel\n",
    "    :param size: size of kernel\n",
    "    :param sizey: get y size\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    y, x = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    gx = - x * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    gy = - y * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    return gx,gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    '''\n",
    "     Function to normalize an input array to 0-1 \n",
    "    '''\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    return (img - img_min) / (img_max - img_min)\n",
    "\n",
    "def my_normalize(matches):\n",
    "    mean_num = np.mean(matches,axis=0)\n",
    "    m_off = np.eye(3,dtype=float)\n",
    "    m_off[0][2],m_off[1][2] = -mean_num[0],-mean_num[1]\n",
    "    m_scale= np.eye(3,dtype=float)\n",
    "    m_scale[0, 0] = 1.0 / max(abs(matches[:, 0]))\n",
    "    m_scale[1, 1] = 1.0 / max(abs(matches[:, 1]))\n",
    "    coor_trans = np.matmul(m_scale,m_off)\n",
    "    noralized_match = np.transpose(np.matmul(coor_trans,\n",
    "                                             np.transpose(matches)))\n",
    "    \n",
    "    return coor_trans,noralized_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function for harris edge detections\n",
    "\"\"\"\n",
    "edge = 16\n",
    "# def harris(filename, min_distance = 10, threshold = 0.1):\n",
    "#     \"\"\"\n",
    "#     filename: Path of image file\n",
    "#     threshold: (optional)Threshold for corner detection\n",
    "#     min_distance : (optional)Minimum number of pixels separating \n",
    "#      corners and image boundary\n",
    "#     \"\"\"\n",
    "#     im = np.array(Image.open(filename).convert(\"L\"))\n",
    "#     harrisim = compute_harris_response(im)\n",
    "#     filtered_coords = get_harris_points(harrisim,min_distance, threshold)\n",
    "#     plot_harris_points(im, filtered_coords)\n",
    "def harris_cornor_detector(img, num_of_points =500):    \n",
    "    direction_x = gaussian_filter1d(\n",
    "        gaussian_filter1d(img.astype(np.float32), 1.0, 0, 0), 1.0, 1, 1\n",
    "    )\n",
    "    direction_y = gaussian_filter1d(gaussian_filter1d(img.astype(np.float32),\n",
    "            1.0, 1, 0), 1.0, 0, 1)\n",
    "    h = (gaussian_filter(direction_x ** 2, 1.5, 0) * gaussian_filter(direction_y ** 2, 1.5, 0) - gaussian_filter(direction_x * direction_y, 1.5, 0)**2) \\\n",
    "        / (gaussian_filter(direction_x**2, 1.5, 0) + gaussian_filter(direction_y**2, 1.5, 0) + 1e-8)\n",
    "    h[:edge, :], h[-edge:, :], h[:, :edge], h[:, -edge:] = 0, 0, 0, 0\n",
    "    mask = h == maximum_filter(h,(8,8))\n",
    "    h = h * mask\n",
    "    final_pairs = np.argsort(h.flatten())[::-1][:num_of_points ]\n",
    "    return np.vstack((final_pairs % img.shape[0:2][1], final_pairs / img.shape[0:2][1], h.flatten()[final_pairs])).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_hood=8 # neighbor numbers\n",
    "\n",
    "\n",
    "def extract_decriptor(img, harris ):\n",
    "    \"\"\"\n",
    "    Function to extract descriptor \n",
    "    :param img:  input image\n",
    "    :param harris: harris cornor \n",
    "    :return: descriptor from detected points\n",
    "    \"\"\"\n",
    "    # Change number here to change the scale. 4 is the optimal amount \n",
    "    y, x = 4 * np.mgrid[-neighbor_hood:neighbor_hood+1, -neighbor_hood:neighbor_hood+1]\n",
    "    descriptor = np.zeros((2 * neighbor_hood + 1, 2 * neighbor_hood + 1, harris.shape[0]), dtype=float)\n",
    "    for i in range(harris.shape[0]):\n",
    "        tmp_points = map_coordinates(img,[harris[i,1] + y, harris[i,0] + x], prefilter=False)\n",
    "        # normalize the descriptor\n",
    "        descriptor[..., i] = (tmp_points - tmp_points.mean()) / tmp_points.std()\n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_from_dist(d1, d2,threshold = 0.7):\n",
    "    \"\"\"\n",
    "        Function to get matches from descriptor according to cdist\n",
    "    \"\"\"\n",
    "    _, width, n = d1.shape[0:3]\n",
    "    #  p1 = np.transpose(np.matrix([correspondence[0].item(0), correspondence[0].item(1), 1]))\n",
    "    # estimatep2 = np.dot(h, p1)\n",
    "    # estimatep2 = (1/estimatep2.item(2))*estimatep2\n",
    "    distance = cdist((d1.reshape((width**2, n))).T, (d2.reshape((width**2, n))).T)\n",
    "    best_current = np.argsort(distance, 1)[:, 0]\n",
    "    # calculate the ration compared to best matches\n",
    "    ratio = distance[np.r_[0:n], best_current] / distance[np.r_[0:n], np.argsort(distance, 1)[:, 1]].mean()\n",
    "    return np.hstack([np.argwhere(ratio < threshold), best_current[np.argwhere(ratio < threshold)]]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_harris_points(harrisim, min_distance=10, threshold=0.1):\n",
    "    \"\"\" return corners from a Harris response image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\"\"\"\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = max(harrisim.ravel()) * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1    \n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_t.nonzero()\n",
    "    coords = [ (candidates[0][c],candidates[1][c]) for c in range(len(candidates[0]))]\n",
    "    #...and their values\n",
    "    candidate_values = [harrisim[c[0]][c[1]] for c in coords]    \n",
    "    #sort candidates\n",
    "    index = argsort(candidate_values)   \n",
    "    #store allowed point locations in array\n",
    "    allowed_locations = zeros(harrisim.shape)\n",
    "    allowed_locations[min_distance:-min_distance,min_distance:-min_distance] = 1   \n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i][0]][coords[i][1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i][0]-min_distance):(coords[i][0]+min_distance),\n",
    "                (coords[i][1]-min_distance):(coords[i][1]+min_distance)] = 0               \n",
    "    return filtered_coords\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homo_coor(points_list):\n",
    "    \"\"\"\n",
    "    :param points_list: 3*N points list\n",
    "    :return: homogeneous coordinates\n",
    "    \"\"\"\n",
    "     # n_outliers = 100\n",
    "     #    all_idxs = numpy.arange( A_noisy.shape[0] )\n",
    "     #    numpy.random.shuffle(all_idxs)\n",
    "     #    outlier_idxs = all_idxs[:n_outliers]\n",
    "           # if 3*N\n",
    "    if points_list.shape[0] == 3:\n",
    "        homo_coordinates = np.zeros_like(points_list)\n",
    "        for i in range(3):\n",
    "            homo_coordinates[i, :] = points_list[i, :] / points_list[2, :]\n",
    "        # divide the last row\n",
    "        #     non_outlier_idxs = all_idxs[n_outliers:]\n",
    "        # A_noisy[outlier_idxs] =  20*numpy.random.random((n_outliers,n_inputs) )\n",
    "        # B_noisy[outlier_idxs] = 50*numpy.random.normal(size=(n_outliers,n_outputs) )\n",
    "    # if 2*N, append np.ones and return \n",
    "    elif points_list.shape[0] == 2: \n",
    "        homo_coordinates = np.vstack((points_list, \n",
    "                         np.ones((1, points_list.shape[1]),dtype=points_list.dtype)))\n",
    "    \n",
    "    return homo_coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cal_homo_Matrix(point1, point2):\n",
    "    \"\"\"\n",
    "    get homography based on two points\n",
    "    :param point1: point1\n",
    "    :param point2: point2\n",
    "    :return: homograph of an image\n",
    "    \"\"\"\n",
    "    A = np.matrix(np.zeros((point1.shape[0]*2, 8), dtype=float), dtype=float)\n",
    "    for i in range(0, A.shape[0]):\n",
    "        if i % 2 == 0:\n",
    "            A[i,0] = point1[i//2,0]\n",
    "            A[i,1] = point1[i//2,1]\n",
    "            A[i,2] = 1\n",
    "            A[i,6] = -point2[i//2,0] * point1[i//2,0]\n",
    "            A[i,7] = -point2[i//2,0] * point1[i//2,1]\n",
    "        else:\n",
    "            A[i,3] = point1[i//2,0]\n",
    "            A[i,4] = point1[i//2,1]\n",
    "            A[i,5] = 1\n",
    "            A[i,6] = -point2[i//2,1] * point1[i//2,0]\n",
    "            A[i,7] = -point2[i//2,1] * point1[i//2,1]\n",
    "    \n",
    "    # get flattened b\n",
    "    b = point2.flatten().reshape(point2.flatten().shape[1], 1).astype(float)\n",
    "    # all_data = numpy.hstack( (A_noisy,B_noisy) )\n",
    "    # input_columns = range(n_inputs) # the first columns of the array\n",
    "    # output_columns = [n_inputs+i for i in range(n_outputs)] # the last columns of the array\n",
    "    # Calculating  A * x = b\n",
    "    x = np.array(np.linalg.lstsq(A,b)[0])\n",
    "    \n",
    "    x = np.append(x,np.matrix(1)).reshape((3,3))\n",
    "    return x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_cornor(homography, img_path):\n",
    "    \"\"\"\n",
    "    get cornors according to homograph\n",
    "    :param homography: \n",
    "    :param img_path: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    mid_point = None\n",
    "    List_C = []\n",
    "    for i in range(len(img_path)):\n",
    "        height, width = cv2.imread(img_path[i]).shape[0:2]\n",
    "        List_C.append(homo_coor(np.dot(homography[i], \n",
    "                                    homo_coor(np.array([[0, width, width, 0], [0, 0, height, height]], dtype=float)))).astype(int))\n",
    "        # if i is half, then midpoint is last of C\n",
    "        # A = numpy.vstack([data[:,i] for i in self.input_columns]).T\n",
    "        # B = numpy.vstack([data[:,i] for i in self.output_columns]).T\n",
    "        # x,resids,rank,s = numpy.linalg.lstsq(A,B)\n",
    "        if i == len(img_path)/2:\n",
    "            mid_point = List_C[-1]\n",
    "    w_list1 = []\n",
    "    w_list2 = []\n",
    "    h_list1 = []\n",
    "    h_list2 = []\n",
    "    for i in range(len(List_C)):\n",
    "        # A = numpy.vstack([data[:,i] for i in self.input_columns]).T\n",
    "        # B = numpy.vstack([data[:,i] for i in self.output_columns]).T\n",
    "        # B_fit = scipy.dot(A,model)\n",
    "        w_list1 += [np.min(List_C[i][0, :])]\n",
    "        h_list1 += [np.min(List_C[i][1, :])]\n",
    "        h_list2 += [np.max(List_C[i][1, :])]\n",
    "        w_list2 += [np.max(List_C[i][0, :])]\n",
    "        \n",
    "    result = np.array([(min(w_list1), min(h_list1)), (max(w_list2), max(h_list2))]), mid_point\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_middle_homo(homo_Matrix,img_size):\n",
    "    \"\"\"\n",
    "    :param homo: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    middle_Homo = []\n",
    "    # cal middle one's homo matrix \n",
    "    homo_Matrix[1] = homo_Matrix[0] * homo_Matrix[1]\n",
    "    for i in range(len(homo_Matrix)):\n",
    "        middle_Homo.append(np.linalg.inv(homo_Matrix[img_size//2]) * homo_Matrix[i])\n",
    "    return middle_Homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # def plot_plane(a, b, c, d):\n",
    " #        xx, yy = np.mgrid[:10, :10]\n",
    " #        return xx, yy, (-d - a * xx - b * yy) / c\n",
    " # \n",
    " #    n = 100\n",
    " #    max_iterations = 100\n",
    " #    goal_inliers = n * 0.3\n",
    "\n",
    "\n",
    "def ransac(Matches, tolerance=0.5, iteration=100):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param Matches: matches selected\n",
    "    :param tolerance: tolerance for model \n",
    "    :param iteration: max iteration number\n",
    "    :return: homo_matrix\n",
    "    \"\"\"\n",
    "    # counter for iteration cnt\n",
    "    count = 0\n",
    "    # record last best model info\n",
    "    last_consensus_cnt = 0\n",
    "    last_homo,last_count = None, None\n",
    "    print(\"Matches shape\",Matches.shape)\n",
    "    \n",
    "    while count < iteration:\n",
    "        sample_points = np.copy(Matches)\n",
    "        tmp_Matches = np.matrix(np.copy(Matches))\n",
    "       \n",
    "        #      try ransac for inliers\n",
    "        # m, b = run_ransac(xyzs, estimate, lambda x, y: is_inlier(x, y, 0.01), 3, goal_inliers, max_iterations)\n",
    "        # a, b, c, d = m\n",
    "        # xx, yy, zz = plot_plane(a, b, c, d)\n",
    "        # ax.plot_surface(xx, yy, zz, color=(0, 1, 0, 0.5))\n",
    "\n",
    "        # Gets a random set of points on RANSAC\n",
    "        np.random.shuffle(sample_points)\n",
    "\n",
    "        # get 4 sample points\n",
    "        sample_points = np.matrix(sample_points)[0:4]\n",
    "        # get homo matrix based on this two points\n",
    "        homo_matrix = cal_homo_Matrix(sample_points[:,0:2], sample_points[:,2:4])\n",
    "        residual_tmp = np.power(np.array(np.array(homo_coor((homo_matrix * homo_coor(tmp_Matches[:,0:2].transpose())))[0:2,:]) \n",
    "                                  - tmp_Matches[:,2:].transpose()),2)\n",
    "        # cal the residual of this model\n",
    "        residual = np.sqrt(residual_tmp.sum(0))\n",
    "        less_than_tol_cnt = (residual < tolerance).sum()\n",
    "        # if new model is better than model before\n",
    "        \n",
    "            #      best_ic = 0\n",
    "            # best_model = None\n",
    "            # random.seed(random_seed)\n",
    "            # # random.sample cannot deal with \"data\" being a numpy array\n",
    "            # data = list(data)\n",
    "        \n",
    "        if last_consensus_cnt < less_than_tol_cnt  :\n",
    "            # update homo\n",
    "            last_homo = homo_matrix\n",
    "            last_consensus_cnt = (residual < tolerance).sum()\n",
    "            last_count = np.argwhere(residual < tolerance)\n",
    "            \n",
    "            Matrix_P = float(last_consensus_cnt) / Matches.shape[0]\n",
    "           \n",
    "            # update iteration number according to Matrix P\n",
    "            itertation = math.log(0.05) * (1/math.log(1-(np.power(Matrix_P,4))))\n",
    "            \n",
    "        count += 1\n",
    "    print(\"number of homo inliers :\", last_consensus_cnt)\n",
    "    print(\"residual:\", np.sum(residual)/residual.size**2)\n",
    "    return last_homo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transformation(image, middle, Cornors):\n",
    "    \"\"\"\n",
    "     transorm image based on homography\n",
    "    :param im: image \n",
    "    :param middle: middle points\n",
    "    :param Cornors: Cornor\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    tmp_y, tmp_x = np.mgrid[Cornors[0, 1]:Cornors[1, 1],\n",
    "                   Cornors[0, 0]:Cornors[1, 0]]\n",
    "    \n",
    "    height = Cornors[1, 1] - Cornors[0, 1]\n",
    "    width = Cornors[1, 0] - Cornors[0, 0] \n",
    "    # change to homo coordinate\n",
    "    #    p1 = np.matrix([corr.item(0), corr.item(1), 1])\n",
    "    #     p2 = np.matrix([corr.item(2), corr.item(3), 1])\n",
    "    # \n",
    "    A = homo_coor(np.dot(np.linalg.inv(middle), homo_coor(np.vstack((tmp_x.flatten(), tmp_y.flatten())))))\n",
    "    x_a = A[0,:].reshape((height, width))\n",
    "    y_a = A[1,:].reshape((height, width))\n",
    "    #     a2 = [0, 0, 0, -p2.item(2) * p1.item(0), -p2.item(2) * p1.item(1), -p2.item(2) * p1.item(2),\n",
    "    #           p2.item(1) * p1.item(0), p2.item(1) * p1.item(1), p2.item(1) * p1.item(2)]\n",
    "    #     a1 = [-p2.item(2) * p1.item(0), -p2.item(2) * p1.item(1), -p2.item(2) * p1.item(2), 0, 0, 0,\n",
    "    #           p2.item(0) * p1.item(0), p2.item(0) * p1.item(1), p2.item(0) * p1.item(2)]\n",
    "    \n",
    "    result = np.zeros((height, width, image.shape[2]), dtype=image.dtype)\n",
    "    if image.ndim == 3:\n",
    "        for dimension in range(image.shape[2]):\n",
    "            #need broadcast here\n",
    "            result[..., dimension] = map_coordinates(image[..., dimension], [y_a, x_a])\n",
    "    else:\n",
    "        result = map_coordinates(image, [y_a, x_a])\n",
    "        \n",
    "    # matrixA = np.matrix(aList)\n",
    "    # \n",
    "    # #svd composition\n",
    "    # u, s, v = np.linalg.svd(matrixA)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_blending(img_path, middle_homo,blend_sigma ):\n",
    "    \"\"\"\n",
    "    :param img_path: all images\n",
    "    :param middle_homo: middle homo \n",
    "    :return: blending result\n",
    "    \"\"\"\n",
    "    tmp_image_list = []\n",
    "    # blend sigma higher, then incoming image more vague\n",
    "    blend_sigma = float(blend_sigma)\n",
    "    for i in range(len(img_path)):\n",
    "        im = cv2.imread(img_path[i])\n",
    "        y_size, x_size = np.mgrid[0:im.shape[0], 0:im.shape[1]]\n",
    "        im = np.dstack((im, np.exp(-((y_size - im.shape[0]/2) ** 2 + (x_size - im.shape[1]/2) ** 2) / (2.0 * blend_sigma ** 2)))) \n",
    "        tmp_image_list.append(image_transformation(im, np.array(middle_Homo[i]), cal_cornor(middle_Homo, img_path)[0]))\n",
    "        \n",
    "\n",
    "    Matrix1 = np.zeros(tmp_image_list[0].shape, dtype=float)\n",
    "    Matrix2 = np.zeros(tmp_image_list[0].shape, dtype=float)\n",
    "    Matrix2[:,:,3] = np.float(1.0)\n",
    "    for i in range(len(tmp_image_list)):\n",
    "        Matrix1[:,:,0] = Matrix1[:,:,0] + tmp_image_list[i][:,:,3] * tmp_image_list[i][:,:,0]\n",
    "        Matrix1[:,:,1] = Matrix1[:,:,1] + tmp_image_list[i][:,:,3] * tmp_image_list[i][:,:,1]\n",
    "        Matrix1[:,:,2] = Matrix1[:,:,2] + tmp_image_list[i][:,:,3] * tmp_image_list[i][:,:,2]\n",
    "        Matrix1[:,:,3] = Matrix1[:,:,3] + tmp_image_list[i][:,:,3]\n",
    "        \n",
    "        Matrix2[:,:,0] =  Matrix2[:,:,0] + tmp_image_list[i][:,:,3]\n",
    "        Matrix2[:,:,1] = Matrix2[:,:,1] + tmp_image_list[i][:,:,3]\n",
    "        Matrix2[:,:,2] = Matrix2[:,:,2] + tmp_image_list[i][:,:,3]\n",
    "        \n",
    "    Matrix2[Matrix2 == 0] = 1\n",
    "    return Matrix1/Matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_1_left_path = \"data\\\\part1\\\\Image1.jpg\"\n",
    "# img_1_right_path = \"data\\\\part1\\\\Image2.jpg\"\n",
    "img_1_left_path = \"data\\\\part1\\\\left.jpg\"\n",
    "img_1_right_path = \"data\\\\part1\\\\right.jpg\"\n",
    "\n",
    "# hill\n",
    "hill_left_path = \"data\\\\part1\\\\hill\\\\1.jpg\"\n",
    "hill_mid_path = \"data\\\\part1\\\\hill\\\\2.jpg\"\n",
    "hill_right_path =\"data\\\\part1\\\\hill\\\\3.jpg\"\n",
    "# ledge\n",
    "ledge_left_path = \"data\\\\part1\\\\ledge\\\\1.jpg\"\n",
    "ledge_mid_path = \"data\\\\part1\\\\ledge\\\\2.jpg\"\n",
    "ledge_part =  \"data\\\\part1\\\\ledge\\\\stitched_image.jpg\"\n",
    "ledge_right_path = \"data\\\\part1\\\\ledge\\\\3.jpg\"\n",
    "# pier\n",
    "pier_left_path = \"data\\\\part1\\\\pier\\\\1.jpg\"\n",
    "pier_mid_path = \"data\\\\part1\\\\pier\\\\2.jpg\"\n",
    "pier_right_path = \"data\\\\part1\\\\pier\\\\3.jpg\"\n",
    "\n",
    "# output folder path\n",
    "out_path = \"data\\\\part1\\\\output\\\\\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workable for sample image left and right\n",
    "# 0.7 and 0.8 very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of initial_matches: 115\nMatches shape (115, 4)\nnumber of homo inliers :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluerain\\PycharmProjects\\cvmp2\\new_venv\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24\nresidual: 8.026359160548154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of initial_matches: 154\nMatches shape (154, 4)\nnumber of homo inliers : 27\nresidual: 1.3348454154824463\n"
     ]
    }
   ],
   "source": [
    "# path of all images\n",
    "img_path = [ledge_left_path,ledge_mid_path, ledge_right_path]\n",
    "homo_Matrix = [np.matrix(np.identity(3))]\n",
    "\n",
    "for i in range(len(img_path) - 1):\n",
    "    # read gray scale image first \n",
    "    img1 = cv2.imread(img_path[i],0)\n",
    "    img2 = cv2.imread(img_path[i+1],0)\n",
    "    # harris cornor detector\n",
    "    harris_points2 = harris_cornor_detector(img2, num_of_points=500)\n",
    "    harris_points1 = harris_cornor_detector(img1, num_of_points=500)\n",
    "\n",
    "    # display feature points of first image\n",
    "    # plt.imshow(img1,cmap='gray')\n",
    "    # for points in harris_points1:\n",
    "    #     plt.scatter(points[0], points[1])\n",
    "    #     plt.draw()\n",
    "    # plt.show()\n",
    "    # \n",
    "    # # display feature points of second image\n",
    "    # plt.imshow(img2,cmap='gray')\n",
    "    # for points in harris_points2:\n",
    "    #     plt.scatter(points[0], points[1])\n",
    "    #     plt.draw()\n",
    "    # plt.show()\n",
    "    \n",
    "    # extract neighbors as descriptors\n",
    "    descriptor_1 = extract_decriptor(img1, harris_points1)\n",
    "    descriptor_2 = extract_decriptor(img2, harris_points2)\n",
    "    \n",
    "    # we can adjust the threshold to have more or less matches\n",
    "    initial_matches = get_match_from_dist(descriptor_1, \n",
    "                       descriptor_2,\n",
    "                       threshold=0.7)\n",
    "    \n",
    "    print(\"num of initial_matches:\", len(initial_matches))\n",
    "    \n",
    "    # we can adjust the tolerance for better model\n",
    "    selected_points = np.matrix(np.hstack((harris_points1[initial_matches[:,0],0:2], harris_points2[initial_matches[:,1],0:2])))\n",
    "    h = ransac(selected_points, tolerance=0.5, iteration=300)\n",
    "    homo_Matrix.append(np.linalg.inv(h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_Homo = cal_middle_homo(homo_Matrix, len(img_path))\n",
    "\n",
    "result_img = image_blending(img_path, middle_Homo,blend_sigma = 100)\n",
    "\n",
    "# print(\"panorama image:\")\n",
    "# plt.imshow(normalize(result_img))\n",
    "# normalize(result_img),cmap='')\n",
    "# plt.show()\n",
    "cv2.imwrite(out_path+\"stitched_image.jpg\", result_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
