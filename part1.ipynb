{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage.filters import correlate \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg \n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gray_to_double(path):\n",
    "    '''\n",
    "    :param path: path to load image\n",
    "    :return: grayscaled and float image\n",
    "    '''\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # transmit the image to float\n",
    "    img = img.astype(np.float64)/255.0\n",
    "\n",
    "    print(img.shape)\n",
    "    return img\n",
    "\n",
    "def load_rgb(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def normalize(img):\n",
    "    ''' Function to normalize an input array to 0-1 '''\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    return (img - img_min) / (img_max - img_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Harris Corner Detector\n",
    "Usage: Call the function harris(filename) for corner detection\n",
    "Reference   (Code adapted from):\n",
    "             http://www.kaij.org/blog/?p=89\n",
    "             Kai Jiang - Harris Corner Detector in Python\n",
    "             \n",
    "\"\"\"\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def harris(filename, min_distance = 10, threshold = 0.1):\n",
    "    \"\"\"\n",
    "    filename: Path of image file\n",
    "    threshold: (optional)Threshold for corner detection\n",
    "    min_distance : (optional)Minimum number of pixels separating \n",
    "     corners and image boundary\n",
    "    \"\"\"\n",
    "    im = np.array(Image.open(filename).convert(\"L\"))\n",
    "    harrisim = compute_harris_response(im)\n",
    "    filtered_coords = get_harris_points(harrisim, min_distance, threshold)\n",
    "    plot_harris_points(im, filtered_coords)\n",
    "    return filtered_coords\n",
    "\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\" returns x and y derivatives of a 2D \n",
    "        gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    y, x = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    gx = - x * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    gy = - y * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    return gx,gy\n",
    "\n",
    "def gauss_kernel(size, sizey = None):\n",
    "    \"\"\" Returns a normalized 2D gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    x, y = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    g = exp(-(x**2/float(size)+y**2/float(sizey)))\n",
    "    return g / g.sum()\n",
    "\n",
    "def compute_harris_response(im):\n",
    "    \"\"\" compute the Harris corner detector response function \n",
    "        for each pixel in the image\"\"\"\n",
    "    #derivatives\n",
    "    gx,gy = gauss_derivative_kernels(3)\n",
    "    imx = signal.convolve(im,gx, mode='same')\n",
    "    imy = signal.convolve(im,gy, mode='same')\n",
    "    #kernel for blurring\n",
    "    gauss = gauss_kernel(3)\n",
    "    #compute components of the structure tensor\n",
    "    Wxx = signal.convolve(imx*imx,gauss, mode='same')\n",
    "    Wxy = signal.convolve(imx*imy,gauss, mode='same')\n",
    "    Wyy = signal.convolve(imy*imy,gauss, mode='same')   \n",
    "    #determinant and trace\n",
    "    Wdet = Wxx*Wyy - Wxy**2\n",
    "    Wtr = Wxx + Wyy   \n",
    "    return Wdet / Wtr\n",
    "\n",
    "def get_harris_points(harrisim, min_distance=10, threshold=0.1):\n",
    "    \"\"\" return corners from a Harris response image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\"\"\"\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = max(harrisim.ravel()) * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1    \n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_t.nonzero()\n",
    "    coords = [ (candidates[0][c],candidates[1][c]) for c in range(len(candidates[0]))]\n",
    "    #...and their values\n",
    "    candidate_values = [harrisim[c[0]][c[1]] for c in coords]    \n",
    "    #sort candidates\n",
    "    index = argsort(candidate_values)   \n",
    "    #store allowed point locations in array\n",
    "    allowed_locations = zeros(harrisim.shape)\n",
    "    allowed_locations[min_distance:-min_distance,min_distance:-min_distance] = 1   \n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i][0]][coords[i][1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i][0]-min_distance):(coords[i][0]+min_distance),\n",
    "                (coords[i][1]-min_distance):(coords[i][1]+min_distance)] = 0               \n",
    "    return filtered_coords\n",
    "\n",
    "def plot_harris_points(image, filtered_coords):\n",
    "    \"\"\" plots corners found in image\"\"\"\n",
    "    figure()\n",
    "    gray()\n",
    "    imshow(image)\n",
    "    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'r*')\n",
    "    axis('off')\n",
    "    show()\n",
    "\n",
    "#harris('./CS543_ECE549 Assignment 3_files/sample_panorama.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract  descriptor\n",
    "\n",
    "\"\"\"\n",
    "def descriptor_extract(img, neighborhoods, feature_points):\n",
    "    num_of_features_ponts = len(feature_points)\n",
    "    print(num_of_features_ponts)\n",
    "    descriptors = np.zeros((num_of_features_ponts, (2*neighborhoods+1)**2))\n",
    "    tmp_img = img.copy()\n",
    "    \n",
    "    for i in range(num_of_features_ponts):\n",
    "        # obtain img slices\n",
    "        # !! Remember to +1 for slice right part! \n",
    "        tmp_img = img[feature_points[i][0]-neighborhoods:\n",
    "                      feature_points[i][0]+neighborhoods+1,\n",
    "                  feature_points[i][1]-neighborhoods:\n",
    "                  feature_points[i][1]+neighborhoods+1]\n",
    "        descriptors[i, :] = tmp_img.reshape((1, (2*neighborhoods+1)**2))\n",
    "        \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC\n",
    "# matches: number * \n",
    "# ((points_left_x,points_right_y,points_right_x,points_right_y))\n",
    "def RANSAC(matches):\n",
    "    num_Of_selected = len(matches)\n",
    "    sample_numbers = 4\n",
    "    threshold = 5\n",
    "    iterations = 300\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        if sample_numbers == 4:\n",
    "            # get sample from matches\n",
    "            inliers = random.sample(num_Of_selected ,sample_numbers)\n",
    "        A = []\n",
    "        for j in range(sample_numbers):\n",
    "            current_match = matches[inliers[j]]\n",
    "            \n",
    "    \n",
    "function [inliers, num_of_inliers, mean_of_residual, H_re] = RANSAC(matches)\n",
    "\n",
    "    % threshold\n",
    "    threshold = 5;\n",
    "    \n",
    "    % num of iterations\n",
    "    iterations = 250;\n",
    "\n",
    "    % Use four matches to initialize the homography in each iteration. \n",
    "    num_of_samples = 4;\n",
    "    n = 1;    \n",
    "    num_of_matches = size(matches, 1);\n",
    "\n",
    "    while(n < iterations)\n",
    "        if num_of_samples == 4\n",
    "            inliers = randsample(num_of_matches, num_of_samples);\n",
    "        end\n",
    "        A = [];\n",
    "        for i = 1:num_of_samples\n",
    "            current_match = matches(inliers(i), :);\n",
    "            xT = [current_match(2), current_match(1), 1];\n",
    "            A = [A; xT*0, xT, xT*(-current_match(3))];\n",
    "            A = [A; xT, xT*0, xT*(-current_match(4))];\n",
    "        end\n",
    "        \n",
    "        % Homography fitting calls for homogeneous least squares.\n",
    "        [~, ~, V] = svd(A);\n",
    "        H = V(:, end);\n",
    "        H_re = reshape(H, 3, 3);\n",
    "        \n",
    "        num_of_inliers = 0;\n",
    "        inliers = [];\n",
    "        residual = [];\n",
    "        for i = 1:num_of_matches\n",
    "            X =  H_re' * [matches(i, 2); matches(i, 1); 1];\n",
    "            x = X(1) / X(3);\n",
    "            y = X(2) / X(3);\n",
    "            if (dist2([x, y], [matches(i, 4), matches(i, 3)]) < threshold)\n",
    "                inliers = [inliers; i];\n",
    "                residual = [residual; dist2([x,y], [matches(i, 4), matches(i, 3)])];\n",
    "                num_of_inliers = num_of_inliers + 1;\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if (num_of_inliers < 15)\n",
    "            num_of_samples = 4;\n",
    "        else\n",
    "           num_of_samples = num_of_inliers;\n",
    "           n = n + 1;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    mean_of_residual = mean(residual);\n",
    "    num_of_inliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_img(img, sigma):\n",
    "    print(img.shape)\n",
    "    tmp_img = img\n",
    "    kernel = gauss_kernel(2*sigma+1)\n",
    "    print(img.ndim)\n",
    "    if img.ndim == 3:\n",
    "        for i in range(img.ndim):\n",
    "            tmp_img[:, :, i] = correlate(tmp_img[:, :, i], kernel)\n",
    "    else:\n",
    "        tmp_img = correlate(tmp_img, kernel)\n",
    "    return tmp_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1_left_path = \"data\\\\part1\\\\left.jpg\"\n",
    "img_1_right_path = \"data\\\\part1\\\\right.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 800)\n(398, 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluerain\\PycharmProjects\\cvmp2\\new_venv\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "img1_left_rgb = load_rgb(img_1_left_path)\n",
    "img1_right_rgb = load_rgb(img_1_right_path)\n",
    "img1_left_gray = load_gray_to_double(img_1_left_path)\n",
    "img1_right_gray = load_gray_to_double(img_1_right_path)\n",
    "# img1_left = load_image(img_1_left_path)\n",
    "# img1_right = load_image(img_2_right_path)\n",
    "# show_img(img1_left)\n",
    "# show_img(img1_right)\n",
    "neighborhoods = 5\n",
    "\n",
    "# harris Cornor detect feature points \n",
    "feature_points_left = harris(img_1_left_path, min_distance=2*neighborhoods)\n",
    "feature_points_right = harris(img_1_right_path, min_distance=2*neighborhoods)\n",
    "# print(feature_points_left)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n376\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract local neighborhoods around every keypoint in both images\n",
    "and form descriptors simply by \"flattening\" the pixel values in each neighborhood \n",
    "to one-dimensional vectors.\n",
    "\"\"\"\n",
    "descriptor_left = descriptor_extract(img1_left_gray, \n",
    "                                      neighborhoods, feature_points_left)\n",
    "descriptor_right = descriptor_extract(img1_right_gray, \n",
    "                                       neighborhoods, feature_points_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 376)\n(598, 121)\n(376, 121)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSelect putative matches based on the matrix of pairwise descriptor distances obtained above. \\nYou can select all pairs whose descriptor distances are below a specified threshold, \\nor select the top few hundred descriptor pairs with the smallest pairwise distances.\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute distances between every descriptor in one image and every descriptor in the other image. \n",
    "In Python, you can use scipy.spatial.distance.cdist(X,Y,'sqeuclidean') \n",
    "for fast computation of Euclidean distance. \n",
    "\"\"\"\n",
    "# dim of distance: num_Of_left * num_of_right\n",
    "distance = cdist(descriptor_left, descriptor_right, 'sqeuclidean')\n",
    "\"\"\"\n",
    "Select putative matches based on the matrix of pairwise descriptor distances obtained above. \n",
    "You can select all pairs whose descriptor distances are below a specified threshold, \n",
    "or select the top few hundred descriptor pairs with the smallest pairwise distances.\n",
    "\"\"\"\n",
    "\n",
    "# num of points to extract \n",
    "total_select_numbers = min(300, len(feature_points_right), len(feature_points_left))\n",
    "select_match = []\n",
    "INF = 11111\n",
    "for i in range(total_select_numbers):\n",
    "    # find matrix minimum index\n",
    "    ri, ci = numpy.unravel_index(A.argmin(), A.shape)\n",
    "    select_match += [(feature_points_left[ri][0],feature_points_left[ri][1],\n",
    "                      feature_points_right[ci][0],feature_points_right[ci][1])]\n",
    "    # set to INF after used\n",
    "    distance[ri, :] = INF\n",
    "    distance[:, ci] = INT\n",
    "    \n",
    "\"\"\"\n",
    "Implement RANSAC to estimate a homography mapping one image onto the other. \n",
    "Report the number of inliers and the average residual for the inliers \n",
    "(squared distance between the point coordinates in one image and\n",
    " the transformed coordinates of the matching point in the other image). \n",
    "Also, display the locations of inlier matches in both images.\n",
    "\"\"\"\n",
    " \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
