{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage.filters import correlate \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg \n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import distance\n",
    "from scipy import *\n",
    "from scipy import linalg\n",
    "from scipy import ndimage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gray_to_double(path):\n",
    "    '''\n",
    "    :param path: path to load image\n",
    "    :return: grayscaled and float image\n",
    "    '''\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # transmit the image to float\n",
    "    img = img.astype(np.float64)/255.0\n",
    "\n",
    "    print(img.shape)\n",
    "    return img\n",
    "\n",
    "def load_rgb(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def normalize(img):\n",
    "    ''' Function to normalize an input array to 0-1 '''\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    return (img - img_min) / (img_max - img_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Harris Corner Detector\n",
    "Usage: Call the function harris(filename) for corner detection\n",
    "Reference   (Code adapted from):\n",
    "             http://www.kaij.org/blog/?p=89\n",
    "             Kai Jiang - Harris Corner Detector in Python\n",
    "             \n",
    "\"\"\"\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def harris(filename, min_distance = 10, threshold = 0.1):\n",
    "    \"\"\"\n",
    "    filename: Path of image file\n",
    "    threshold: (optional)Threshold for corner detection\n",
    "    min_distance : (optional)Minimum number of pixels separating \n",
    "     corners and image boundary\n",
    "    \"\"\"\n",
    "    im = np.array(Image.open(filename).convert(\"L\"))\n",
    "    harrisim = compute_harris_response(im)\n",
    "    filtered_coords = get_harris_points(harrisim, min_distance, threshold)\n",
    "    plot_harris_points(im, filtered_coords)\n",
    "    return filtered_coords\n",
    "\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\" returns x and y derivatives of a 2D \n",
    "        gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    y, x = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    gx = - x * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    gy = - y * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    return gx,gy\n",
    "\n",
    "def gauss_kernel(size, sizey = None):\n",
    "    \"\"\" Returns a normalized 2D gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    x, y = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    g = exp(-(x**2/float(size)+y**2/float(sizey)))\n",
    "    return g / g.sum()\n",
    "\n",
    "def compute_harris_response(im):\n",
    "    \"\"\" compute the Harris corner detector response function \n",
    "        for each pixel in the image\"\"\"\n",
    "    #derivatives\n",
    "    gx,gy = gauss_derivative_kernels(3)\n",
    "    imx = signal.convolve(im,gx, mode='same')\n",
    "    imy = signal.convolve(im,gy, mode='same')\n",
    "    #kernel for blurring\n",
    "    gauss = gauss_kernel(3)\n",
    "    #compute components of the structure tensor\n",
    "    Wxx = signal.convolve(imx*imx,gauss, mode='same')\n",
    "    Wxy = signal.convolve(imx*imy,gauss, mode='same')\n",
    "    Wyy = signal.convolve(imy*imy,gauss, mode='same')   \n",
    "    #determinant and trace\n",
    "    Wdet = Wxx*Wyy - Wxy**2\n",
    "    Wtr = Wxx + Wyy   \n",
    "    return Wdet / Wtr\n",
    "\n",
    "def get_harris_points(harrisim, min_distance=10, threshold=0.1):\n",
    "    \"\"\" return corners from a Harris response image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\"\"\"\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = max(harrisim.ravel()) * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1    \n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_t.nonzero()\n",
    "    coords = [ (candidates[0][c],candidates[1][c]) for c in range(len(candidates[0]))]\n",
    "    #...and their values\n",
    "    candidate_values = [harrisim[c[0]][c[1]] for c in coords]    \n",
    "    #sort candidates\n",
    "    index = argsort(candidate_values)   \n",
    "    #store allowed point locations in array\n",
    "    allowed_locations = zeros(harrisim.shape)\n",
    "    allowed_locations[min_distance:-min_distance,min_distance:-min_distance] = 1   \n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i][0]][coords[i][1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i][0]-min_distance):(coords[i][0]+min_distance),\n",
    "                (coords[i][1]-min_distance):(coords[i][1]+min_distance)] = 0               \n",
    "    return filtered_coords\n",
    "\n",
    "def plot_harris_points(image, filtered_coords):\n",
    "    \"\"\" plots corners found in image\"\"\"\n",
    "    figure()\n",
    "    gray()\n",
    "    imshow(image)\n",
    "    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'r*')\n",
    "    axis('off')\n",
    "    show()\n",
    "\n",
    "#harris('./CS543_ECE549 Assignment 3_files/sample_panorama.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_images(image0, image1, transform):\n",
    "    r, c = image1.shape[:2]\n",
    "    # Note that transformations take coordinates in (x, y) format,\n",
    "    # not (row, column), in order to be consistent with most literature\n",
    "    corners = np.array([[0, 0],\n",
    "                        [0, r],\n",
    "                        [c, 0],\n",
    "                        [c, r]])\n",
    "\n",
    "    # Warp the image corners to their new positions\n",
    "    warped_corners = transform(corners)\n",
    "\n",
    "    # Find the extents of both the reference image and the warped\n",
    "    # target image\n",
    "    all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "    corner_min = np.min(all_corners, axis=0)\n",
    "    corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "    output_shape = (corner_max - corner_min)\n",
    "    output_shape = np.ceil(output_shape[::-1])\n",
    "\n",
    "    offset = SimilarityTransform(translation=-corner_min)\n",
    "\n",
    "    image0_ = warp(image0, offset.inverse, output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image1_ = warp(image1, (transform + offset).inverse, output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image0_zeros = warp(image0, offset.inverse, output_shape=output_shape, cval=0)\n",
    "\n",
    "    image1_zeros = warp(image1, (transform + offset).inverse, output_shape=output_shape, cval=0)\n",
    "\n",
    "    overlap = (image0_ != -1.0 ).astype(int) + (image1_ != -1.0).astype(int)\n",
    "    overlap += (overlap < 1).astype(int)\n",
    "    merged = (image0_zeros+image1_zeros)/overlap\n",
    "\n",
    "    im = Image.fromarray((255*merged).astype('uint8'), mode='RGB')\n",
    "    im.save('stitched_images.jpg')\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract  descriptor\n",
    "    returns a descriptor of size numoffeature * (neighbor+1)*(neighbor+1)\n",
    "\"\"\"\n",
    "def descriptor_extract(img, neighborhoods, feature_points):\n",
    "    num_Of_points = len(feature_points)\n",
    "    print(num_Of_points)\n",
    "    descriptors = np.zeros((num_Of_points, (2*neighborhoods+1)**2))\n",
    "    tmp_img = img.copy()\n",
    "    \n",
    "    for i in range(num_Of_points):\n",
    "        # obtain img slices\n",
    "        # !! Remember to +1 for slice right part! \n",
    "        tmp_img = img[feature_points[i][0]-neighborhoods:\n",
    "                      feature_points[i][0]+neighborhoods+1,\n",
    "                  feature_points[i][1]-neighborhoods:\n",
    "                  feature_points[i][1]+neighborhoods+1]\n",
    "        descriptors[i, :] = tmp_img.reshape((1, (2*neighborhoods+1)**2))\n",
    "        \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      0    109     37      1 -30193 -10249   -277]\n [   109     37      1      0      0      0 -23653  -8029   -217]\n [     0      0      0    135     48      1 -22275  -7920   -165]\n [   135     48      1      0      0      0 -31455 -11184   -233]\n [     0      0      0    134    289      1  -2948  -6358    -22]\n [   134    289      1      0      0      0 -13266 -28611    -99]\n [     0      0      0    235     71      1 -66740 -20164   -284]\n [   235     71      1      0      0      0 -25850  -7810   -110]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.54770610e-03 -5.58058075e-03 -4.80399703e-01]\n [ 6.12870951e-03 -9.48045825e-04 -8.76994036e-01]\n [ 3.69461232e-05 -5.96446869e-05 -2.70129349e-03]]\n"
     ]
    }
   ],
   "source": [
    "Matrix = []\n",
    "sample_numbers = 4\n",
    "matches = np.random.randint(1,300,(300,4))\n",
    "inliers = np.random.choice(300,4)\n",
    "for j in range(sample_numbers):\n",
    "    current_match = matches[inliers[j]]\n",
    "    #left feature point\n",
    "    xt = np.array([current_match[1], current_match[0], 1]).T\n",
    "    new_row = np.append(np.append(xt*0, xt), xt*-current_match[2])\n",
    "    # new_row = np.array([0*xt,xt,-current_match[2]*xt])\n",
    "    new_row2 =np.append(np.append(xt, xt * 0), xt * -current_match[3])\n",
    "    if len(Matrix) == 0:\n",
    "        Matrix = new_row\n",
    "    else:\n",
    "        Matrix = np.vstack([Matrix, new_row])\n",
    "    Matrix = np.vstack([Matrix, new_row2])\n",
    "\n",
    "print(Matrix)\n",
    "_,_,VMatrix = np.linalg.svd(Matrix)\n",
    "HMatrix = VMatrix[len(VMatrix)-1]\n",
    "H_reshape = np.reshape(HMatrix, (3, 3))\n",
    "print(H_reshape)\n",
    "\n",
    "def dist2(x,y):   \n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "# RANSAC\n",
    "# matches: numberof features * 2 coords\n",
    "# ((points_left_x,points_right_y,points_right_x,points_right_y))\n",
    "def RANSAC(matches, threshold = 10, iterations = 250, good_model_num = 15):\n",
    "    sample_numbers = 4\n",
    "    match_number = len(matches)\n",
    "    print(\"num of matches\", match_number)\n",
    "    # start number for each iteration\n",
    "    cnt = 1\n",
    "    model_error = 255\n",
    "    while cnt < iterations: \n",
    "        # get 4 random samples from matches\n",
    "        if sample_numbers == 4:\n",
    "            # get sample from matches\n",
    "            inliers = np.random.choice(match_number, sample_numbers)\n",
    "        \n",
    "\n",
    "       \n",
    "        A = np.array([])\n",
    "        # for each sample:\n",
    "        for j in range(sample_numbers):\n",
    "            current_match = matches[inliers[j]]\n",
    "            #left feature point\n",
    "            xt = np.array([current_match[1], current_match[0], 1]).T\n",
    "            new_row = np.append(np.append(xt*0, xt), xt*-current_match[2])\n",
    "            # new_row = np.array([0*xt,xt,-current_match[2]*xt])\n",
    "            new_row2 =np.append(np.append(xt, xt * 0), xt * -current_match[3])\n",
    "            if len(A) == 0:\n",
    "                A = new_row\n",
    "            else:\n",
    "                A = np.vstack([A, new_row])\n",
    "            A = np.vstack([A, new_row2])\n",
    "        \n",
    "        # Homography fitting\n",
    "        _,_,VMatrix = np.linalg.svd(A)\n",
    "        HMatrix = VMatrix[len(VMatrix)-1]\n",
    "        H_reshape = np.reshape(HMatrix, (3, 3))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # consensus_set = []\n",
    "        # for i in range(len(matches)):\n",
    "        #     x1,y1 = matches[i][0],matches[i][1]\n",
    "        #     x2,y2 = matches[i][2],matches[i][3]\n",
    "        #     A = array([x1, y1, 1]).reshape(3,1)\n",
    "        #     B = array([x2, y2, 1]).reshape(3,1)\n",
    "        #     out = B - dot(H_reshape, A)\n",
    "        #     dist_err = hypot(out[0][0], out[1][0])\n",
    "        #     if dist_err < threshold:\n",
    "        #         consensus_set.append(matches[i])\n",
    "        #         \n",
    "        # # Check how well is our speculated model\n",
    "        # if len(consensus_set) >= good_model_num:\n",
    "        #     dists = []\n",
    "        #     for p in consensus_set:\n",
    "        #         x0, y0 = p[0],p[1]\n",
    "        #         x1, y1 = p[2],p[3]\n",
    "        # \n",
    "        #         A = array([x0, y0, 1]).reshape(3,1)\n",
    "        #         B = array([x1, y1, 1]).reshape(3,1)\n",
    "        # \n",
    "        #         out = B - dot(H_reshape, A)\n",
    "        #         dist_err = hypot(out[0][0], out[1][0])\n",
    "        #         dists.append(dist_err)\n",
    "        #     if (max(dists) < threshold) and (max(dists) < model_error):\n",
    "        #         model_error = max(dists)\n",
    "        #         model_H = H_reshape\n",
    "        # if model_H is None:\n",
    "        #     print(\"No result!\")\n",
    "        # else:\n",
    "        #     return model_H\n",
    "        \n",
    "        # print(H_reshape)\n",
    "        inliers_number = 0\n",
    "        inliers = []\n",
    "        residual = []\n",
    "        for i in range(len(matches)):\n",
    "            right_tmp =  np.array([matches[i][1],matches[i][0], 1])\n",
    "            X = np.matmul(np.transpose(H_reshape),\n",
    "                            right_tmp)\n",
    "            x, y= X[0]/X[2],X[1]/X[2]\n",
    "\n",
    "            sample_point = np.array([x, y])\n",
    "            match_point = np.array([matches[i][3], matches[i][2]])\n",
    "            # print(sample_point)\n",
    "            # print(match_point)\n",
    "            tmpDis = np.linalg.norm(sample_point-match_point)\n",
    "\n",
    "            # print(tmpDis)\n",
    "            if tmpDis < threshold:\n",
    "                inliers += [i]\n",
    "                residual += [tmpDis]\n",
    "                inliers_number += 1\n",
    "\n",
    "        if inliers_number < good_model_num:\n",
    "            sample_numbers = 4\n",
    "            # print(\"inliernumber:\",inliers_number)\n",
    "        else:\n",
    "            sample_numbers = inliers_number\n",
    "            cnt += 1\n",
    "            # print(\"got one\")\n",
    "\n",
    "    print(\"num of iterations:\",cnt)\n",
    "    mean_of_residual = np.mean(residual)\n",
    "    print(inliers_number)    \n",
    "    if H_reshape is None:\n",
    "        print(\"no model got\")\n",
    "    return  H_reshape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_features(img_l,img_r,matches,final_matches):\n",
    "    implot_l = plt.imshow(img_l)\n",
    "    print(len(matches))\n",
    "    print(len(final_matches))\n",
    "    for i in range(len(matches)):\n",
    "        plt.scatter(x=matches[i][1], y=matches[i][0], c='r', s=10)\n",
    "    for i in range(len(final_matches)):\n",
    "        plt.scatter(x=final_matches[i][1], y=final_matches[i][0], c='g', s=10)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    implot_r = plt.imshow(img_r)\n",
    "    for i in range(len(matches)):\n",
    "        plt.scatter(x=matches[i][3], y=matches[i][2], c='r', s=10)\n",
    "    for i in range(len(final_matches)):\n",
    "        plt.scatter(x=final_matches[i][3], y=final_matches[i][2], c='g', s=10)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_img(img, sigma):\n",
    "    print(img.shape)\n",
    "    tmp_img = img\n",
    "    kernel = gauss_kernel(2*sigma+1)\n",
    "    print(img.ndim)\n",
    "    if img.ndim == 3:\n",
    "        for i in range(img.ndim):\n",
    "            tmp_img[:, :, i] = correlate(tmp_img[:, :, i], kernel)\n",
    "    else:\n",
    "        tmp_img = correlate(tmp_img, kernel)\n",
    "    return tmp_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Haffine_from_points(fp,tp):\n",
    "    \"\"\" \n",
    "        Find affine transform\n",
    "    \"\"\"\n",
    "\n",
    "    if fp.shape != tp.shape:\n",
    "        raise RuntimeError\n",
    "\n",
    "    #condition points\n",
    "    #-from points-\n",
    "    m = mean(fp[:2], axis=1)\n",
    "    maxstd = max(std(fp[:2], axis=1))\n",
    "    C1 = diag([1/maxstd, 1/maxstd, 1])\n",
    "    C1[0][2] = -m[0]/maxstd\n",
    "    C1[1][2] = -m[1]/maxstd\n",
    "    fp_cond = dot(C1,fp)\n",
    "\n",
    "    #-to points-\n",
    "    m = mean(tp[:2], axis=1)\n",
    "    C2 = C1.copy() #must use same scaling for both point sets\n",
    "    C2[0][2] = -m[0]/maxstd\n",
    "    C2[1][2] = -m[1]/maxstd\n",
    "    tp_cond = dot(C2,tp)\n",
    "\n",
    "    #conditioned points have mean zero, so translation is zero\n",
    "    A = concatenate((fp_cond[:2],tp_cond[:2]), axis=0)\n",
    "    U,S,V = linalg.svd(A.T)\n",
    "\n",
    "    #create B and C matrices as Hartley-Zisserman (2:nd ed) p 130.\n",
    "    tmp = V[:2].T\n",
    "    B = tmp[:2]\n",
    "    C = tmp[2:4]\n",
    "\n",
    "    tmp2 = concatenate((dot(C,linalg.pinv(B)),zeros((2,1))), axis=1)\n",
    "    H = vstack((tmp2,[0,0,1]))\n",
    "\n",
    "    #decondition\n",
    "    H = dot(linalg.inv(C2),dot(H,C1))\n",
    "\n",
    "    return H / H[2][2]\n",
    "\n",
    "def get_homography(points_list):\n",
    "    '''\n",
    "        Function to quickly compute a homography matrix from all point \n",
    "        correspondences.\n",
    "        Inputs:\n",
    "            points_list: tuple of tuple of tuple of correspondence indices. Each\n",
    "            entry is [[x1, y1], [x2, y2]] where [x1, y1] from image 1 corresponds\n",
    "            to [x2, y2] from image 2.\n",
    "        Outputs:\n",
    "            H: Homography matrix.\n",
    "    '''\n",
    "    fp = ones((len(plist), 3))\n",
    "    tp = ones((len(plist), 3))\n",
    "\n",
    "    for idx in range(len(plist)):\n",
    "        fp[idx, 0] = plist[idx][0][0]\n",
    "        fp[idx, 1] = plist[idx][0][1]\n",
    "\n",
    "        tp[idx, 0] = plist[idx][1][0]\n",
    "        tp[idx, 1] = plist[idx][1][1]\n",
    "\n",
    "    H = Haffine_from_points(fp.T, tp.T)\n",
    "\n",
    "    return H\n",
    "\n",
    "from random import choice\n",
    "\n",
    "\n",
    "def ransac(im1, im2, points_list, iters = 500 , error = 10, good_model_num = 5):\n",
    "    if ndim(im1) == 2:\n",
    "        rows,cols = im1.shape\n",
    "    else:\n",
    "        rows, cols, _ = im1.shape\n",
    "    model_error = 255\n",
    "    model_H = None\n",
    "\n",
    "    for i in range(iters):\n",
    "        consensus_set = []\n",
    "        points_list_temp = copy(points_list).tolist()\n",
    "        # Randomly select 3 points\n",
    "        for j in range(3):\n",
    "            temp = choice(points_list_temp)\n",
    "            consensus_set.append(temp)\n",
    "            points_list_temp.remove(temp)\n",
    "            \n",
    "        # Calculate the homography matrix\n",
    "    \n",
    "        fp0 = []\n",
    "        fp1 = []\n",
    "        fp2 = []\n",
    "    \n",
    "        tp0 = []\n",
    "        tp1 = []\n",
    "        tp2 = []\n",
    "        for line in consensus_set:\n",
    "    \n",
    "            fp0.append(line[0][0])\n",
    "            fp1.append(line[0][1])\n",
    "            fp2.append(1)\n",
    "    \n",
    "            tp0.append(line[1][0])\n",
    "            tp1.append(line[1][1])\n",
    "            tp2.append(1)\n",
    "    \n",
    "        fp = array([fp0, fp1, fp2])\n",
    "        tp = array([tp0, tp1, tp2])\n",
    "    \n",
    "        H = Haffine_from_points(fp, tp)\n",
    "    \n",
    "        # Transform the second image\n",
    "        # imtemp = transform_im(im2, [-xshift, -yshift], -theta)\n",
    "        # Check if the other points fit this model\n",
    "    \n",
    "        for p in points_list_temp:\n",
    "            x1, y1 = p[0]\n",
    "            x2, y2 = p[1]\n",
    "    \n",
    "            A = array([x1, y1, 1]).reshape(3,1)\n",
    "            B = array([x2, y2, 1]).reshape(3,1)\n",
    "    \n",
    "            out = B - dot(H, A)\n",
    "            dist_err = hypot(out[0][0], out[1][0])\n",
    "            if dist_err < error:\n",
    "                consensus_set.append(p)\n",
    "    \n",
    "    \n",
    "        # Check how well is our speculated model\n",
    "        if len(consensus_set) >= good_model_num:\n",
    "            dists = []\n",
    "            for p in consensus_set:\n",
    "                x0, y0 = p[0]\n",
    "                x1, y1 = p[1]\n",
    "    \n",
    "                A = array([x0, y0, 1]).reshape(3,1)\n",
    "                B = array([x1, y1, 1]).reshape(3,1)\n",
    "    \n",
    "                out = B - dot(H, A)\n",
    "                dist_err = hypot(out[0][0], out[1][0])\n",
    "                dists.append(dist_err)\n",
    "            if (max(dists) < error) and (max(dists) < model_error):\n",
    "                model_error = max(dists)\n",
    "                model_H = H\n",
    "\n",
    "    return model_H\n",
    "\n",
    "def affine_transform2(im, rot, shift):\n",
    "    '''\n",
    "        Perform affine transform for 2/3D images.\n",
    "    '''\n",
    "    if ndim(im) == 2:\n",
    "        return ndimage.affine_transform(im, rot, shift)\n",
    "    else:\n",
    "        imr = ndimage.affine_transform(im[:, :, 0], rot, shift)\n",
    "        img = ndimage.affine_transform(im[:, :, 1], rot, shift)\n",
    "        imb = ndimage.affine_transform(im[:, :, 2], rot, shift)\n",
    "\n",
    "        return dstack((imr, img, imb))\n",
    "    \n",
    "smoothing_window_size = 800\n",
    "def create_mask(img1,img2,version):\n",
    "        height_img1 = img1.shape[0]\n",
    "        width_img1 = img1.shape[1]\n",
    "        width_img2 = img2.shape[1]\n",
    "        height_panorama = height_img1\n",
    "        width_panorama = width_img1 +width_img2\n",
    "        offset = int(smoothing_window_size / 2)\n",
    "        barrier = img1.shape[1] - int(smoothing_window_size / 2)\n",
    "        mask = np.zeros((height_panorama, width_panorama))\n",
    "        if version== 'left_image':\n",
    "            mask[:, barrier - offset:barrier + offset ] = np.tile(np.linspace(1, 0, 2 * offset ).T, (height_panorama, 1))\n",
    "            mask[:, :barrier - offset] = 1\n",
    "        else:\n",
    "            mask[:, barrier - offset :barrier + offset ] = np.tile(np.linspace(0, 1, 2 * offset ).T, (height_panorama, 1))\n",
    "            mask[:, barrier + offset:] = 1\n",
    "        return cv2.merge([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1_left_path = \"data\\\\part1\\\\left.jpg\"\n",
    "img_1_right_path = \"data\\\\part1\\\\right.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 800)\n(398, 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluerain\\PycharmProjects\\cvmp2\\new_venv\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "img1_left_rgb = load_rgb(img_1_left_path)\n",
    "img1_right_rgb = load_rgb(img_1_right_path)\n",
    "img1_left_gray = load_gray_to_double(img_1_left_path)\n",
    "img1_right_gray = load_gray_to_double(img_1_right_path)\n",
    "# img1_left = load_image(img_1_left_path)\n",
    "# img1_right = load_image(img_2_right_path)\n",
    "# show_img(img1_left)\n",
    "# show_img(img1_right)\n",
    "neighborhoods = 5\n",
    "\n",
    "# harris Cornor detect feature points \n",
    "feature_points_left = harris(img_1_left_path, min_distance=2*neighborhoods)\n",
    "feature_points_right = harris(img_1_right_path, min_distance=2*neighborhoods)\n",
    "# print(feature_points_left)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n376\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract local neighborhoods around every keypoint in both images\n",
    "and form descriptors simply by \"flattening\" the pixel values in each neighborhood \n",
    "to one-dimensional vectors.\n",
    "\"\"\"\n",
    "from scipy.stats import zscore\n",
    "\n",
    "descriptor_left = descriptor_extract(img1_left_gray, \n",
    "                                      neighborhoods, feature_points_left)\n",
    "descriptor_right = descriptor_extract(img1_right_gray, \n",
    "                                       neighborhoods, feature_points_right)\n",
    "#Normalize to zero mean\n",
    "norm_descriptor_left = zscore(descriptor_left)\n",
    "\n",
    "norm_descriptor_right = zscore(descriptor_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 376)\nnum of matches 300\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\ngot one\nnum of iterations: 300\n23\n[[-3.51860781e-04 -1.44205803e-03  4.55366065e-01]\n [-7.65155172e-04 -2.99741993e-03  8.90285462e-01]\n [-4.11181898e-06 -1.51708916e-05  4.66583266e-03]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-4ca703f39107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# H_ransac = inv(out_ransac)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mH_ransac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_ransac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mwarp_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1_left_rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg1_left_rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH_ransac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m# height_img1 = img1_left_rgb.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# width_img1 = img1_left_gray.shape[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-0f8b95927f58>\u001b[0m in \u001b[0;36mwarp_images\u001b[0;34m(image0, image1, transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Warp the image corners to their new positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwarped_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Find the extents of both the reference image and the warped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\"\"\"\n",
    "Compute distances between every descriptor in one image and every descriptor in the other image. \n",
    "In Python, you can use scipy.spatial.distance.cdist(X,Y,'sqeuclidean') \n",
    "for fast computation of Euclidean distance. \n",
    "\"\"\"\n",
    "# dim of distance: num_Of_left * num_of_right\n",
    "distance = cdist(norm_descriptor_left, norm_descriptor_right, 'sqeuclidean')\n",
    "print(distance.shape)\n",
    "\"\"\"\n",
    "Select putative matches based on the matrix of pairwise descriptor distances obtained above. \n",
    "You can select all pairs whose descriptor distances are below a specified threshold, \n",
    "or select the top few hundred descriptor pairs with the smallest pairwise distances.\n",
    "\"\"\"\n",
    "\n",
    "# num of points to extract \n",
    "total_select_numbers = min(300, len(feature_points_right), len(feature_points_left))\n",
    "select_match = []\n",
    "INF = 1111111\n",
    "for i in range(total_select_numbers):\n",
    "    # find matrix minimum index\n",
    "    ri, ci = np.unravel_index(distance.argmin(), distance.shape)\n",
    "    select_match += [(feature_points_left[ri][0],feature_points_left[ri][1],\n",
    "                      feature_points_right[ci][0],feature_points_right[ci][1])]\n",
    "    # set to INF after used\n",
    "    distance[ri, :] = INF\n",
    "    distance[:, ci] = INF\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Implement RANSAC to estimate a homography mapping one image onto the other. \n",
    "Report the number of inliers and the average residual for the inliers \n",
    "(squared distance between the point coordinates in one image and\n",
    " the transformed coordinates of the matching point in the other image). \n",
    "Also, display the locations of inlier matches in both images.\n",
    "\"\"\"\n",
    "# [inliers, inliers_number, mean_of_residual, H] = RANSAC(select_match,\n",
    "#                                                         threshold=220,\n",
    "#                                                         good_model_num=10)\n",
    "# final_Match = []\n",
    "# print(\"final match number is\",inliers_number)\n",
    "# for i in range(inliers_number):\n",
    "#     final_Match += [select_match[inliers[i]]]\n",
    "# \n",
    "# # show features\n",
    "# show_features(img1_left_rgb,img1_right_rgb,\n",
    "#               select_match,  final_Match)\n",
    "\n",
    "# points_list = [[[matches[0],matches[1]],[matches[2],matches[3]]] for matches in select_match]\n",
    "# out_ransac = ransac(img1_left_rgb,img1_right_gray,points_list,good_model_num=6)\n",
    "\n",
    "out_ransac = RANSAC(select_match,iterations=300, threshold=255,good_model_num=10)\n",
    "print(out_ransac)\n",
    "# H_ransac = inv(out_ransac)\n",
    "H_ransac = out_ransac\n",
    "warp_images(img1_left_rgb,img1_left_rgb,H_ransac)\n",
    "height_img1 = img1_left_rgb.shape[0]\n",
    "width_img1 = img1_left_gray.shape[1]\n",
    "width_img2 = img1_right_gray.shape[1]\n",
    "height_panorama = height_img1\n",
    "width_panorama = width_img1 +width_img2\n",
    "\n",
    "panorama1 = np.zeros((height_panorama, width_panorama, 3))\n",
    "mask1 = create_mask(img1_left_rgb, img1_right_rgb,version='left_image')\n",
    "panorama1[0:img1_left_rgb.shape[0], 0:img1_left_rgb.shape[1], :] = img1_left_rgb\n",
    "panorama1 *= mask1\n",
    "mask2 = create_mask(img1_left_rgb, img1_right_rgb,version='right_image')\n",
    "panorama2 = cv2.warpPerspective(img1_right_rgb, H_ransac, (width_panorama, height_panorama))*mask2\n",
    "result= panorama1+panorama2\n",
    "\n",
    "rows, cols = np.where(result[:, :, 0] != 0)\n",
    "min_row, max_row = min(rows), max(rows) + 1\n",
    "min_col, max_col = min(cols), max(cols) + 1\n",
    "final_result = result[min_row:max_row, min_col:max_col, :]\n",
    "show_img(normalize(final_result))\n",
    "print(final_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
